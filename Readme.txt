amplicon-length-analysis.py 统计长度，主要是在primer pair里面用了，其实平时也可以通用

class_SILVA_aligned_transform.py 用于把SILVA的aligned initial拆分成3个文件再用于统计，注意：每个文件的结尾缺少一个换行符，所以如果直接文件与文件拼接的话，会少了一行。这个程序还会把.都改成-

conserved_region_summary.sh 计算好ATCG出现频率以后，统计保守区的整个流程

count_freq_micro_database.R 计算aligned_silva的每个位置的ATCG出现频率，用于做整个保守区统计的流程conserved_region_summary.sh中的第二步

coverage_calculate.R 计算引物覆盖数和整体背景的比例，用于引物覆盖度计算primer_coverage_estimator.sh的流程中的2.1步骤

extract_taxa_by_faID.R 利用fa文件里面的ID去获取全长ID，最后获取实际的taxonomy列表，是文件间比对的任务，用于引物覆盖度计算primer_coverage_estimator.sh的流程中的2.1步骤(逻辑是用引物扩增的denoveID，通过_grouped_full_ID.txt匹配ID，最后再匹配_uniq_strain.tax里的taxa，但是这个做法是旧的并且多余的，因此这个脚本被extract_taxa_by_ID.R代替了

extract_taxa_by_ID.R 直接利用引物扩增的ID和_uniq_strain.tax的taxa匹配。

intersect_uniq_taxaID.R uniqID和taxaID找交集，是一个比较特殊情况下用的功能，SILVA_EZ_GG_database_merge.sh数据库合并的流程中的3.2步骤

mark_ref_order.R 对unaligned的一条序列进行位置注释，是保守区统计的预处理的一个步骤，并不在流程中出现

PCAS_CRs_update_pip.sh 为了简化更新以及作为记录，新增了这个流程做CR区的更新

primer_coverage_estimator.sh 统计单一引物的覆盖度情况的整体流程,2020.1重新更新，大大提高了效率，也去除了不必要的好几个步骤。

primer_pair_coverage_estimator.sh 统计单一引物对的覆盖度情况的整体流程

SILVA_conserved_region_summary_loop_phylum.sh 对SILVAalign的每个门下面的每个界进行保守度统计的命令,为了减少后面上传的工作量，输出的命名改成了界名-门名-后缀的形式。

SILVA_EZ_GG_database_merge.sh 数据库合并的流程

single_database_analysis.sh 对单一数据库（或者合并后的也行），进行去重分析和tax重命名并且生成后续primer覆盖度分析所需要的主要两个输入文件

Split_fasta_base_on_domain.py 把一个含有tax的fa，分解成三个界以及其他。（注，可能只对SILVA的格式有效）

summary_aligned_ref_length.py 存粹就是检查aligned_ref的长度的，用于做整个保守区统计的流程conserved_region_summary.sh中的第一步

summary_freq.R 对具体的ATCG比例的连贯性进行，整个保守区统计的流程conserved_region_summary.sh中的第三步，也是核心

